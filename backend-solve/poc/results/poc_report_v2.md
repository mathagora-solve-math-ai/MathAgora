# PoC Report v2: LLM Step-by-Step 풀이 정렬 검증

> 실험일: 2026-02-10
> 실험자: 고운 편
> 대상 문제: 2024학년도 수능 수학(홀수) 공통 7번 (수학2, 3점)
> API: OpenAI (GPT-5.2), OpenRouter (나머지)

### v1 → v2 변경사항

| 항목 | v1 | v2 |
|------|-----|-----|
| Task 1 모델 | GPT-4o | **GPT-5.2** |
| Task 2 모델 | GPT-4o, Claude Sonnet 4, Gemini 2.5 Flash | **GPT-5.2, Claude Opus 4.5, Gemini 3 Pro** |
| Task 3 모델 | GPT-4o | **GPT-5.2** |
| Task 4 모델 | GPT-4o, Claude Sonnet 4, Gemini 2.5 Flash, Llama 4 Maverick, Qwen 3 235B | **GPT-5.2, Claude Opus 4.5, Gemini 3 Pro, Grok 4, minimax-m2.1** |
| GPT API 라우팅 | OpenRouter (전체) | **GPT-5.2는 OpenAI 직접 호출** (BYOK 제한) |

---

## 실험 대상 문제

**2024학년도 수능 수학 7번**

> 함수 $f(x)=\dfrac{1}{3}x^3-2x^2-12x+4$가 $x=\alpha$에서 극대이고 $x=\beta$에서 극소일 때, $\beta-\alpha$의 값은?
>
> ① -4 ② -1 ③ 2 ④ 5 ⑤ **8** (정답)

---

## Task 1. 프롬프트 버전별 Step 구조화 품질

3가지 프롬프트로 동일 문제를 **GPT-5.2** (temperature=0.3)에게 풀게 한 뒤, 응답에서 step을 추출하여 구조화 품질을 비교한다.

### 프롬프트 설계

| 버전 | 프롬프트 핵심 지시 |
|------|--------------------|
| v1_simple | "다음 수학 문제를 풀어주세요." |
| v2_step | "다음 수학 문제를 **단계별(step-by-step)**로 풀어주세요." |
| v3_titled | "단계별로 풀되, 각 단계마다 **간결한 제목**을 붙여주세요." + `[STEP title="..."]` 출력 포맷 명시 |

### 결과

| 버전 | 추출 step 수 | 응답 시간 | 제목 품질 | 정답 |
|------|:-----------:|:---------:|----------|:----:|
| v1_simple | **6** | 4.7s | 없음 (Part 1~6 fallback) | 8 |
| v2_step | **13** | 7.2s | Markdown 헤딩 ("## 1) 도함수 구하기") | 8 |
| v3_titled | **4 + Final Answer** | 4.9s | 명시적 한국어 제목 ("도함수 구하기", "극값 조건(임계점) 찾기" 등) | 8 |

### v1_simple 추출 결과 (GPT-5.2)

파싱 방식: paragraph 분리 (줄바꿈 2개 기준)

```
Part 1:  함수 f(x)의 극대/극소는 도함수 f'(x)=0 에서 발생합니다.
Part 2:  1) 도함수: f'(x) = x^2 - 4x - 12
Part 3:  2) 임계점 구하기: (x-6)(x+2)=0 → x=6, x=-2
Part 4:  3) 극대/극소 판별(이차도함수): f''(-2)<0 극대, f''(6)>0 극소
Part 5:  4) β-α = 6-(-2) = 8
Part 6:  정답: ⑤ 8
```

- v1(GPT-4o)에서 15개로 과분할되던 것이 GPT-5.2에서는 6개로 간결해짐
- GPT-5.2가 지시 없이도 번호를 매기는 경향이 있으나, paragraph 기준 파싱이라 구조 불안정

### v2_step 추출 결과 (GPT-5.2)

파싱 방식: Markdown 헤딩 + 번호 패턴

```
## 1) 도함수 구하기
## 2) 극값 조건: f'(x)=0 풀기
## 3) 극대/극소 판단
## 4) β-α 계산
## 정답
```

- GPT-5.2가 Markdown 헤딩(`##`)을 적극 사용 → 번호 패턴으로는 4개 step 추출
- 헤딩 사이에 구분선(`---`)이 삽입되어 paragraph fallback 시 13개로 과분할됨
- 제목은 있지만 추출 안정성이 포맷 의존적

### v3_titled 추출 결과 (GPT-5.2)

파싱 방식: `[STEP title="..."]` 마커 기반 정규식 파싱

```
[1] 도함수 구하기:        f'(x) = x^2 - 4x - 12
[2] 극값 조건(임계점) 찾기: (x-6)(x+2)=0 → x=-2, x=6
[3] 극대/극소 위치 판별:   f'(x) 부호 변화로 x=-2 극대, x=6 극소 확인
[4] 차이 계산:            β-α = 6-(-2) = 8
[FINAL_ANSWER] 8 (⑤)
```

- 마커 기반으로 정확하게 4+1 step 파싱됨
- GPT-5.2에서도 포맷 지시 준수율 100%
- 제목이 간결하고 일관적

### Task 1 결론

> **v3_titled 프롬프트가 GPT-5.2에서도 step 구조화에 최적이다.**
> - GPT-5.2는 v1에서도 비교적 간결하게 응답하지만(v1: GPT-4o 15개 → GPT-5.2 6개), v3_titled의 명시적 마커가 가장 안정적
> - v2에서 GPT-5.2가 Markdown 헤딩 + 구분선을 사용하는 경향 → heuristic 파싱 시 주의 필요
> - 응답 속도가 전반적으로 빨라짐 (GPT-4o 대비 약 50% 단축)

### v1 vs v2 비교 (Task 1)

| 지표 | v1 (GPT-4o) | v2 (GPT-5.2) |
|------|:-----------:|:------------:|
| v1_simple step 수 | 15 | **6** |
| v2_step step 수 | 5 | 13 (구분선 포함) |
| v3_titled step 수 | 4+1 | **4+1** (동일) |
| v3_titled 응답 시간 | 5.8s | **4.9s** |

---

## Task 2. 코사인 유사도 기반 Step 정렬 검증

v3_titled 프롬프트로 3개 모델(**GPT-5.2, Claude Opus 4.5, Gemini 3 Pro**)의 풀이를 받고, step 간 TF-IDF 코사인 유사도로 유사한 풀이 단계끼리 자동 정렬(alignment)되는지 검증한다.

### 실험 설정

- 프롬프트: v3_titled
- temperature: 0.3
- 유사도: char n-gram (2~4) TF-IDF 코사인 유사도
- alignment threshold: 0.3
- 그룹핑: Union-Find (서로 다른 모델의 step만 연결)

### 모델별 추출된 Step

| # | GPT-5.2 | Claude Opus 4.5 | Gemini 3 Pro |
|:-:|---------|-----------------|--------------|
| 1 | 도함수 구하기 | 도함수 구하기 | 도함수 구하기 |
| 2 | 임계점(극값 후보) 찾기 | 임계점 찾기 | 인수분해 및 0이 되는 값 찾기 |
| 3 | 극대/극소 판별 | 극대와 극소 판별 | 극대, 극소 판별 |
| 4 | 요구값 계산 | β - α 계산 | 최종 계산 |
| 5 | Final Answer | Final Answer | Final Answer |

### 발견된 Alignment Group (4개)

| Group | 포함 모델 | 매칭된 Step | 대표 유사도 |
|:-----:|:---------:|------------|:----------:|
| **G1** | 3/3 | GPT "도함수 구하기" ↔ Claude "도함수 구하기" ↔ Gemini "도함수 구하기" | 0.32 ~ 0.62 |
| **G2** | 3/3 | GPT "Final Answer" ↔ Claude "Final Answer" ↔ Gemini "Final Answer" | 0.42 ~ 0.69 |
| **G3** | 2/3 | Claude "임계점 찾기" ↔ Gemini "인수분해 및 0이 되는 값 찾기" | 0.55 |
| **G4** | 2/3 | Claude "β - α 계산" ↔ Gemini "최종 계산" | 0.68 |

### 주요 Cross-solution 유사도 (상위)

| 유사도 | Model A - Step | Model B - Step |
|:------:|----------------|----------------|
| 0.689 | Claude "Final Answer" | Gemini "Final Answer" |
| 0.676 | Claude "β - α 계산" | Gemini "최종 계산" |
| 0.624 | Claude "도함수 구하기" | Gemini "도함수 구하기" |
| 0.565 | GPT "도함수 구하기" | Gemini "도함수 구하기" |
| 0.553 | Claude "임계점 찾기" | Gemini "인수분해 및 0이 되는 값 찾기" |
| 0.519 | GPT "Final Answer" | Gemini "Final Answer" |
| 0.423 | GPT "Final Answer" | Claude "Final Answer" |
| 0.323 | GPT "도함수 구하기" | Claude "도함수 구하기" |

### Task 2 결론

> **최신 모델에서도 코사인 유사도 기반 step 정렬이 잘 동작한다.**
> - 3개 모델 모두 5-step 구조로 수렴하여, v1의 5~6 step보다 일관성 향상
> - 4개 alignment group이 발견되었으며, G1(도함수), G2(Final Answer)는 전원 참여
> - GPT-5.2의 step 제목이 다른 모델과 약간 다른 표현("요구값 계산")을 사용하여 G4에서 제외됨
> - Claude Opus 4.5 ↔ Gemini 3 Pro 간 유사도가 전반적으로 높음 (0.55~0.69)

### v1 vs v2 비교 (Task 2)

| 지표 | v1 | v2 |
|------|:--:|:--:|
| 모델 수 | 3 | 3 |
| Alignment Group 수 | 5 | **4** |
| 3/3 참여 Group | 4 | **2** |
| Step 구조 일관성 | 5~6 step | **전원 5 step** |

---

## Task 3. 단일 모델 다양성 검증

**동일 모델(GPT-5.2)**에 **temperature=1.0**으로 **5회** 반복 추론하여, 풀이의 다양성을 확인한다.

### 실험 설정

- 모델: GPT-5.2 (openai/gpt-5.2)
- 프롬프트: v3_titled
- temperature: 1.0
- 반복 횟수: 5

### Run별 추출된 Step 제목

| Run | Step 수 | Step 제목 목록 |
|:---:|:-------:|---------------|
| 1 | 5 | 도함수 구하기 → 임계점(극값 후보) 찾기 → 극대/극소 판별 → 차이 계산 → Final Answer |
| 2 | 5 | 도함수 구하기 → 임계점(극값 후보) 찾기 → 극대/극소 판별 → 요구값 계산 → Final Answer |
| 3 | 5 | 도함수 구하기 → 임계점(극값 후보) 구하기 → 극대/극소 판별 → 요구값 계산 → Final Answer |
| 4 | 5 | 도함수 구하기 → 임계점(극값 후보) 찾기 → 극대/극소 판별 → 차이 계산 → Final Answer |
| 5 | 5 | 도함수 구하기 → 임계점(극값 후보) 찾기 → 극대/극소 판별 → 요구값 계산 → Final Answer |

### Pairwise 풀이 유사도 (전체 풀이 텍스트 기준)

| | Run 1 | Run 2 | Run 3 | Run 4 | Run 5 |
|-------|:-----:|:-----:|:-----:|:-----:|:-----:|
| Run 1 | - | 0.707 | 0.708 | 0.789 | 0.784 |
| Run 2 | | - | 0.953 | 0.550 | 0.545 |
| Run 3 | | | - | 0.559 | 0.556 |
| Run 4 | | | | - | 0.878 |
| Run 5 | | | | | - |

**평균 pairwise 유사도: 0.703**

### Step-level Alignment

5개 alignment group 발견 — **모든 run의 모든 step이 1:1로 정확히 대응됨**:

| Group | 매칭 |
|:-----:|------|
| G1 | Run 1~5 Step 1: 도함수 구하기 (전원 동일) |
| G2 | Run 1~5 Step 2: 임계점(극값 후보) 찾기/구하기 (전원 동일) |
| G3 | Run 1~5 Step 3: 극대/극소 판별 (전원 동일) |
| G4 | Run 1~5 Step 4: 차이 계산 / 요구값 계산 (전원 동일) |
| G5 | Run 1~5 Step 5: Final Answer (전원 동일) |

### Task 3 결론

> **GPT-5.2는 GPT-4o보다 더 일관된 구조를 생성하나, 그만큼 다양성은 더 낮다.**
> - 평균 유사도 0.703 (v1의 GPT-4o: 0.802)이지만, **step 구조는 5회 전부 동일** (5 step, 동일 제목)
> - GPT-4o는 step 수가 4~9로 편차가 컸으나, GPT-5.2는 5 step으로 완전 수렴
> - 유사도 차이(0.55~0.95)는 풀이 본문의 수식 전개 방식 차이에서 비롯됨 (인수분해 vs 근의 공식 등)
> - **결론 동일: 동일 모델 반복으로는 풀이 전략 다양성 확보 불가**

### v1 vs v2 비교 (Task 3)

| 지표 | v1 (GPT-4o) | v2 (GPT-5.2) |
|------|:-----------:|:------------:|
| 평균 유사도 | 0.802 | **0.703** |
| Step 수 편차 | 4~9개 | **전부 5개** |
| Alignment Group | 1 (뭉쳐버림) | **5 (완벽 1:1 대응)** |
| 구조 일관성 | 낮음 | **매우 높음** |

---

## Task 4. 다중 모델 다양성 검증

**5개 서로 다른 모델**로 동일 문제를 풀어, 모델 간 풀이 다양성을 확인한다.

### 실험 설정

- 프롬프트: v3_titled
- temperature: 0.7
- 모델 5종:

| 약칭 | 모델 ID | API |
|------|--------|-----|
| GPT-5.2 | openai/gpt-5.2 | OpenAI 직접 |
| Claude Opus 4.5 | anthropic/claude-opus-4.5 | OpenRouter |
| Gemini 3 Pro | google/gemini-3-pro-preview | OpenRouter |
| Grok 4 | x-ai/grok-4 | OpenRouter |
| minimax-m2.1 | minimax/minimax-m2.1 | OpenRouter |

### 모델별 추출된 Step 제목

| # | GPT-5.2 | Claude Opus 4.5 | Gemini 3 Pro | Grok 4 | minimax-m2.1 |
|:-:|---------|-----------------|--------------|--------|--------------|
| 1 | 도함수 구하기 | 도함수 구하기 | 도함수 구하기 | 도함수 구하기 | 도함수 구하기 |
| 2 | 극값 조건(임계점) 찾기 | 임계점 찾기 | 임계점 찾기 | 임계점 찾기 | 극점 찾기 |
| 3 | 극대·극소 판별 | 극대와 극소 판별 | 극대·극소 판별 | 2계 도함수 구하기 | 극대·극소 판정 |
| 4 | 요구값 계산 | β - α 계산 | 최종 계산 | 극대/극소 판별 | Final Answer |
| 5 | Final Answer | Final Answer | Final Answer | 차이 계산 | - |
| 6 | - | - | - | Final Answer | - |

### Pairwise 풀이 유사도

| | GPT-5.2 | Claude | Gemini | Grok 4 | minimax |
|------|:-------:|:------:|:------:|:------:|:-------:|
| GPT-5.2 | - | 0.091 | 0.162 | 0.379 | 0.165 |
| Claude | | - | 0.315 | 0.174 | 0.385 |
| Gemini | | | - | 0.218 | 0.515 |
| Grok 4 | | | | - | 0.387 |
| minimax | | | | | - |

**평균 pairwise 유사도: 0.279**

### 발견된 Alignment Group (3개)

| Group | 포함 모델 수 | 매칭 내용 |
|:-----:|:----------:|----------|
| G1 | 5/5 | **도함수 구하기** — 전 모델 Step 1 동일 |
| G2 | 5/5 | **중간 풀이 단계** — 임계점 찾기, 극값 판별, 결과 계산 등이 혼합 클러스터 |
| G3 | 5/5 | **Final Answer** — 전 모델 참여 |

### Task 4 결론

> **최신 모델 조합에서 풀이 다양성이 v1보다 더 높게 나타났다.**
> - 평균 유사도 **0.279** — v1(0.499) 대비 **44% 낮음** → 다양성 대폭 증가
> - GPT-5.2 ↔ Claude Opus 4.5 유사도가 **0.091**로 매우 낮음 — 풀이 본문의 표현/수식 전개가 크게 다름
> - Grok 4가 유일하게 6-step 구조 (2계 도함수를 독립 단계로 분리)
> - minimax-m2.1은 4-step으로 가장 간결 (β-α 계산을 Final Answer에 통합)
> - Gemini 3 Pro ↔ minimax-m2.1 (0.515)이 가장 유사한 쌍

### v1 vs v2 비교 (Task 4)

| 지표 | v1 | v2 |
|------|:--:|:--:|
| 평균 유사도 | 0.499 | **0.279** |
| Alignment Group 수 | 5 | **3** |
| 5/5 참여 Group | 3 | **3** |
| Step 수 범위 | 5~7 | **4~6** |
| 최저 pairwise | 0.314 | **0.091** |
| 최고 pairwise | 0.659 | **0.515** |

---

## 종합 결론 및 시사점

### 1. 프롬프트 전략

**v3_titled (명시적 마커 포맷) 사용을 권장한다.** (v1과 동일 결론)
- GPT-5.2에서도 포맷 준수율 100%, 파싱 안정성 최고
- GPT-5.2는 v1_simple에서도 간결한 응답을 생성하나, 명시적 마커가 가장 확정적
- GPT-5.2의 Markdown 헤딩 사용 경향에 주의 → v2_step 파싱 시 `## N)` 패턴 추가 고려

### 2. Step 정렬 가능성

**char n-gram TF-IDF 코사인 유사도 + Union-Find로 cross-model step 정렬이 최신 모델에서도 잘 동작한다.**
- 최신 모델들이 더 일관된 step 구조를 생성하여 정렬 품질 향상
- GPT-5.2는 독자적 표현("요구값 계산")을 사용하여 일부 group에서 미매칭 → 유사도 threshold 조정 또는 임베딩 기반 유사도 고려

### 3. 다양성 확보 전략

| 전략 | v1 평균 유사도 | v2 평균 유사도 | 다양성 |
|------|:-------------:|:-------------:|:------:|
| 동일 모델, temp=1.0, 5회 | 0.802 | **0.703** | 낮음 |
| 서로 다른 모델 5종 | 0.499 | **0.279** | **매우 높음** |

**핵심 발견:**
- **다중 모델 전략의 우위가 v2에서 더 극대화됨** (유사도 0.279, v1 대비 44% 감소)
- 최신 모델들은 내부적으로 더 다른 풀이 전개를 하여 모델 간 차별화가 뚜렷
- GPT-5.2의 단일 모델 반복은 step 구조까지 완전 동일 → temp 조절만으로는 구조적 다양성 불가

### 4. 모델 특성 요약

| 모델 | Step 수 | 응답 시간 | 특징 |
|------|:-------:|:---------:|------|
| GPT-5.2 | 5 | 4.9~7.4s | 가장 빠르고 일관적, 포맷 준수 우수 |
| Claude Opus 4.5 | 5 | 7.3~7.7s | 안정적, 인수분해 기반 풀이 |
| Gemini 3 Pro | 5 | 15.3~22.3s | 가장 느림, thinking tokens 소비 |
| Grok 4 | 6 | 15.8s | 2계 도함수를 독립 단계로 분리 |
| minimax-m2.1 | 4 | 4.5s | 가장 간결, reasoning 모델 |

### 5. 후속 작업 제안

- [ ] 더 어려운 문제(4점 문항)에서도 동일하게 동작하는지 검증
- [ ] 풀이 전략이 실질적으로 다른 문제(예: 치환적분 vs 부분적분)에 대한 다양성 검증
- [ ] 임베딩 기반 유사도(sentence-transformers 등)와 TF-IDF 비교 — GPT-5.2의 독자적 표현 매칭 개선
- [ ] 프론트엔드 시각화에 연결선(edge) 렌더링 PoC
- [ ] 실시간 스트리밍 중 부분적 alignment 가능성 검토
- [ ] Gemini 3 Pro의 thinking token 비용 최적화 (응답 시간 22초)
