#!/usr/bin/env python3
"""
JSON Schema ê°•ì œ ì¶œë ¥ íŒŒì´í”„ë¼ì¸

ê° ëª¨ë¸(GPT-5.2, Claude Opus 4.5, Gemini 3 Pro)ì´
Generator ì…ë ¥ ìŠ¤í‚¤ë§ˆ í˜•ì‹ìœ¼ë¡œ ì§ì ‘ JSONì„ ì¶œë ¥í•˜ë„ë¡ ê°•ì œí•©ë‹ˆë‹¤.

Input Schema:
{
  "model_name": "gpt-5.2",
  "steps": [
    {"step_idx": 0, "title": "...", "content": "..."},
    {"step_idx": 1, "title": "...", "content": "..."}
  ]
}
"""

import json
import os
import csv
import time
from openai import OpenAI

csv.field_size_limit(10_000_000)

# API Keys and Configuration (set via environment variables)
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY", "")
OPENROUTER_API_KEY = os.environ.get("OPENROUTER_API_KEY", "")
OPENROUTER_BASE_URL = "https://openrouter.ai/api/v1"

# API Clients
def _get_openai_client() -> OpenAI:
    return OpenAI(api_key=OPENAI_API_KEY)

def _get_openrouter_client() -> OpenAI:
    return OpenAI(base_url=OPENROUTER_BASE_URL, api_key=OPENROUTER_API_KEY)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# JSON Schema ì •ì˜ (Generator ì…ë ¥ í˜•ì‹)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def make_solution_schema(prob_type: str) -> dict:
    """ë¬¸ì œ ìœ í˜•ì— ë”°ë¥¸ JSON Schema ìƒì„±

    Args:
        prob_type: '5ì§€ì„ ë‹¤í˜•' ë˜ëŠ” 'ë‹¨ë‹µí˜•'
    """
    if prob_type == "5ì§€ì„ ë‹¤í˜•":
        final_answer_schema = {
            "type": "integer",
            "description": "ìµœì¢… ë‹µ (ê°ê´€ì‹ ì„ íƒì§€ ë²ˆí˜¸: 1~5)",
            "minimum": 1,
            "maximum": 5,
        }
    else:  # ë‹¨ë‹µí˜•
        final_answer_schema = {
            "type": "integer",
            "description": "ìµœì¢… ë‹µ (ë‹¨ë‹µí˜• ì •ìˆ˜: 0~999)",
            "minimum": 0,
            "maximum": 999,
        }

    return {
        "type": "object",
        "properties": {
            "model_name": {
                "type": "string",
                "description": "ëª¨ë¸ ì´ë¦„"
            },
            "steps": {
                "type": "array",
                "description": "í’€ì´ ë‹¨ê³„ ë°°ì—´",
                "items": {
                    "type": "object",
                    "properties": {
                        "step_idx": {
                            "type": "integer",
                            "description": "ë‹¨ê³„ ë²ˆí˜¸ (0ë¶€í„° ì‹œì‘)"
                        },
                        "title": {
                            "type": "string",
                            "description": "ë‹¨ê³„ ì œëª© (ê°„ê²°í•˜ê²Œ, 10ë‹¨ì–´ ì´ë‚´)"
                        },
                        "content": {
                            "type": "string",
                            "description": "ë‹¨ê³„ ë‚´ìš© (ìƒì„¸í•œ í’€ì´)"
                        }
                    },
                    "required": ["step_idx", "title", "content"],
                    "additionalProperties": False
                }
            },
            "final_answer": final_answer_schema,
        },
        "required": ["model_name", "steps", "final_answer"],
        "additionalProperties": False
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# v4 í”„ë¡¬í”„íŠ¸ (ë¶ˆí•„ìš”í•œ ì„¸ë¶„í™” ë°©ì§€)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

V4_PROMPT_TEMPLATE = """ë‹¤ìŒ ìˆ˜í•™ ë¬¸ì œë¥¼ ë‹¨ê³„ë³„ë¡œ í’€ì–´ì£¼ì„¸ìš”.

<problem>
{problem_text}
</problem>

**ì¤‘ìš” ì§€ì¹¨**:
1. ë‹¨ê³„(STEP)ëŠ” í’€ì´ì˜ íë¦„(ì „ëµ/ì ‘ê·¼)ì´ ë°”ë€ŒëŠ” ì§€ì ë§ˆë‹¤ êµ¬ë¶„í•˜ë˜, **ì˜ë¯¸ ì—†ëŠ” ì„¸ë¶„í™”ëŠ” í”¼í•˜ê³  í•„ìš”í•œ ë§Œí¼ë§Œ** ë‚˜ëˆ„ì„¸ìš”
2. ê° ë‹¨ê³„ëŠ” ëª…í™•í•œ ëª©ì ì„ ê°€ì ¸ì•¼ í•©ë‹ˆë‹¤
3. ë¶ˆí•„ìš”í•˜ê²Œ ì„¸ë¶„í™”í•˜ì§€ ë§ˆì„¸ìš” (ì˜ˆ: "ì‹ ì •ë¦¬" â†’ "ê´„í˜¸ í’€ê¸°" â†’ "ë™ë¥˜í•­ ì •ë¦¬" ëŒ€ì‹  "ì‹ ì •ë¦¬"ë¡œ í†µí•©)

**ì¶œë ¥ í˜•ì‹**:
ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:

{{
  "model_name": "{model_name}",
  "steps": [
    {{
      "step_idx": 0,
      "title": "ë‹¨ê³„ ì œëª© (ê°„ê²°í•˜ê²Œ)",
      "content": "ìƒì„¸í•œ í’€ì´ ë‚´ìš©"
    }},
    {{
      "step_idx": 1,
      "title": "...",
      "content": "..."
    }}
  ],
  "final_answer": {final_answer_hint}
}}

**step_idxëŠ” 0ë¶€í„° ì‹œì‘**í•˜ë©°, ìˆœì°¨ì ìœ¼ë¡œ ì¦ê°€í•©ë‹ˆë‹¤.
**titleì€ 10ë‹¨ì–´ ì´ë‚´**ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•©ë‹ˆë‹¤.
**contentëŠ” í•´ë‹¹ ë‹¨ê³„ì˜ êµ¬ì²´ì ì¸ í’€ì´ ê³¼ì •**ì„ í¬í•¨í•©ë‹ˆë‹¤.
**final_answerëŠ” {final_answer_desc}**"""


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# OpenAI Structured Output
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _make_prompt(problem_text: str, model_name: str, prob_type: str) -> str:
    """prob_typeì— ë§ëŠ” final_answer íŒíŠ¸ë¥¼ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    if prob_type == "5ì§€ì„ ë‹¤í˜•":
        hint = "1"
        desc = "ê°ê´€ì‹ ì„ íƒì§€ ë²ˆí˜¸ ì •ìˆ˜ (1~5 ì¤‘ í•˜ë‚˜)"
    else:
        hint = "0"
        desc = "ë‹¨ë‹µí˜• ì •ë‹µ ì •ìˆ˜ (0~999 ì‚¬ì´)"
    return V4_PROMPT_TEMPLATE.format(
        problem_text=problem_text,
        model_name=model_name,
        final_answer_hint=hint,
        final_answer_desc=desc,
    )


def solve_with_openai_structured(problem_text, model_name="openai/gpt-5.2", display_name="gpt-5.2", prob_type="ë‹¨ë‹µí˜•"):
    """OpenAI Structured Outputìœ¼ë¡œ í’€ì´ (OpenAI API ì§ì ‘ ì‚¬ìš©)"""

    prompt = _make_prompt(problem_text, display_name, prob_type)

    # OpenAI API ì§ì ‘ ì‚¬ìš© (structured output ì§€ì›)
    client = _get_openai_client()
    native_model = model_name.split("/", 1)[1] if "/" in model_name else model_name

    response = client.chat.completions.create(
        model=native_model,
        messages=[
            {
                "role": "system",
                "content": "ë‹¹ì‹ ì€ ìˆ˜í•™ ë¬¸ì œ í’€ì´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë¬¸ì œë¥¼ ëª…í™•í•œ ë‹¨ê³„ë¡œ ë‚˜ëˆ„ì–´ í’€ì´í•˜ë˜, ë¶ˆí•„ìš”í•œ ì„¸ë¶„í™”ëŠ” í”¼í•©ë‹ˆë‹¤."
            },
            {"role": "user", "content": prompt}
        ],
        response_format={
            "type": "json_schema",
            "json_schema": {
                "name": "model_solution",
                "strict": True,
                "schema": make_solution_schema(prob_type)
            }
        },
        temperature=0.7
    )

    return json.loads(response.choices[0].message.content)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Anthropic Tool Use (JSON ê°•ì œ)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def solve_with_openrouter_json(problem_text, model_name="anthropic/claude-opus-4.5", display_name="claude-opus-4.5", prob_type="ë‹¨ë‹µí˜•"):
    """OpenRouter APIë¡œ JSON ê°•ì œ (Claude, Gemini ë“±)"""

    prompt = _make_prompt(problem_text, display_name, prob_type)

    # OpenRouter API ì‚¬ìš©
    client = _get_openrouter_client()

    try:
        response = client.chat.completions.create(
            model=model_name,
            messages=[
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ ìˆ˜í•™ ë¬¸ì œ í’€ì´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë¬¸ì œë¥¼ ëª…í™•í•œ ë‹¨ê³„ë¡œ ë‚˜ëˆ„ì–´ í’€ì´í•˜ë˜, ë¶ˆí•„ìš”í•œ ì„¸ë¶„í™”ëŠ” í”¼í•©ë‹ˆë‹¤. ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”."
                },
                {"role": "user", "content": prompt}
            ],
            response_format={"type": "json_object"},  # JSON mode
            temperature=0.7,
            max_tokens=8000
        )

        result = json.loads(response.choices[0].message.content)
        return result

    except Exception as e:
        print(f"  âš ï¸  OpenRouter JSON mode error, trying without format constraint: {e}")
        # Fallback: without response_format
        response = client.chat.completions.create(
            model=model_name,
            messages=[
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ ìˆ˜í•™ ë¬¸ì œ í’€ì´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë¬¸ì œë¥¼ ëª…í™•í•œ ë‹¨ê³„ë¡œ ë‚˜ëˆ„ì–´ í’€ì´í•˜ë˜, ë¶ˆí•„ìš”í•œ ì„¸ë¶„í™”ëŠ” í”¼í•©ë‹ˆë‹¤. ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”."
                },
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=8000
        )

        content = response.choices[0].message.content
        # Try to extract JSON from markdown code blocks
        if "```json" in content:
            content = content.split("```json")[1].split("```")[0].strip()
        elif "```" in content:
            content = content.split("```")[1].split("```")[0].strip()

        return json.loads(content)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ëª¨ë“  OpenRouter ëª¨ë¸ì€ solve_with_openrouter_json ì‚¬ìš©
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Pipeline
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def process_problem_json_enforced(prob_id, prob_text, prob_type="ë‹¨ë‹µí˜•", output_dir='outputs/json_enforced'):
    """
    1ê°œ ë¬¸ì œë¥¼ JSON ê°•ì œ ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬

    ê° ëª¨ë¸ì´ Generator ì…ë ¥ ìŠ¤í‚¤ë§ˆ í˜•ì‹ìœ¼ë¡œ ì§ì ‘ ì¶œë ¥
    â†’ Generatorì— ì…ë ¥ â†’ Flow Map ìƒì„±
    """

    print(f"\n{'='*60}")
    print(f"Processing: {prob_id}")
    print(f"{'='*60}")

    os.makedirs(output_dir, exist_ok=True)

    # ëª¨ë¸ ì„¤ì • (OpenRouter model IDs)
    models = {
        'gpt-5.2': {
            'api_model': 'openai/gpt-5.2',  # OpenAI API ì§ì ‘ ì‚¬ìš©
            'function': solve_with_openai_structured
        },
        'claude-opus-4.5': {
            'api_model': 'anthropic/claude-opus-4.5',  # OpenRouter ì‚¬ìš©
            'function': solve_with_openrouter_json
        },
        'gemini-3-pro': {
            'api_model': 'google/gemini-3-pro-preview',  # OpenRouter ì‚¬ìš©
            'function': solve_with_openrouter_json
        }
    }

    solutions = []

    # 1. ê° ëª¨ë¸ì—ì„œ JSON ê°•ì œ í’€ì´ ìƒì„±
    for display_name, config in models.items():
        print(f"\n[{display_name}] Solving with JSON schema enforcement...")

        try:
            solution = config['function'](
                problem_text=prob_text,
                model_name=config['api_model'],
                display_name=display_name,
                prob_type=prob_type,
            )

            if solution:
                solutions.append(solution)
                print(f"  âœ“ Generated {len(solution['steps'])} steps")
            else:
                print(f"  âœ— Failed to generate solution")

        except Exception as e:
            print(f"  âœ— Error: {e}")
            continue

        time.sleep(2)  # Rate limit

    # 2. JSON ì €ì¥ (Generator ì…ë ¥ í˜•ì‹)
    generator_input = {
        'problem_text': prob_text,
        'solutions': solutions
    }

    input_path = os.path.join(output_dir, f'input_{prob_id}.json')
    with open(input_path, 'w', encoding='utf-8') as f:
        json.dump(generator_input, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… Saved Generator input: {input_path}")

    # 3. Generator í˜¸ì¶œí•˜ì—¬ Flow Map ìƒì„±
    try:
        from generator import generate_flow_map
        from schemas import FlowMapInput, ModelSolution, Step

        # Convert dict to schema objects
        model_solutions = []
        for sol_dict in solutions:
            steps = [
                Step(
                    step_idx=s['step_idx'],
                    title=s['title'],
                    content=s['content']
                )
                for s in sol_dict['steps']
            ]
            model_solutions.append(
                ModelSolution(
                    model_name=sol_dict['model_name'],
                    steps=steps
                )
            )

        flowmap_input = FlowMapInput(
            problem_text=prob_text,
            solutions=model_solutions
        )

        flowmap = generate_flow_map(flowmap_input)

        flowmap_path = os.path.join(output_dir, f'flowmap_{prob_id}.json')
        with open(flowmap_path, 'w', encoding='utf-8') as f:
            json.dump(flowmap.to_dict(), f, ensure_ascii=False, indent=2)

        print(f"âœ… Generated Flow Map: {flowmap_path}")
        print(f"   - Groups: {len(flowmap.groups)}")
        print(f"   - Flows: {len(flowmap.flows)}")

        return flowmap

    except Exception as e:
        print(f"âš ï¸  Flow Map generation failed: {e}")
        return None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Main
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    """2024ë…„ë„ 46ë¬¸ì œ ì²˜ë¦¬"""

    print("="*70)
    print(" JSON Schema ê°•ì œ ì¶œë ¥ íŒŒì´í”„ë¼ì¸ (v4 Prompt)")
    print("="*70)
    print()
    print("ê° ëª¨ë¸ì´ Generator ì…ë ¥ ìŠ¤í‚¤ë§ˆ í˜•ì‹ìœ¼ë¡œ ì§ì ‘ JSON ì¶œë ¥")
    print("â†’ Generatorì— ì…ë ¥ â†’ Flow Map ìƒì„±")
    print()

    # 2024 ìˆ˜ëŠ¥ í™€ìˆ˜ ë¬¸ì œ ë¡œë“œ
    csv_path = '../data/2024_math_odd.csv'

    problems = []
    with open(csv_path, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            problems.append({
                'prob_id': row['prob_id'],
                'prob_type': row.get('prob_type', 'ë‹¨ë‹µí˜•'),
                'prob_desc': row['prob_desc'],
                'prob_area': row.get('prob_area', ''),
                'prob_point': row.get('prob_point', ''),
                'answer': row.get('answer', '')
            })

    print(f"ğŸ“š Total problems: {len(problems)}\n")

    # ì²˜ë¦¬
    output_dir = 'outputs/json_enforced'
    success_count = 0
    summary = []

    for i, prob in enumerate(problems, 1):
        print(f"\n{'#'*70}")
        print(f"# Problem {i}/{len(problems)}")
        print(f"{'#'*70}")

        try:
            flowmap = process_problem_json_enforced(
                prob['prob_id'],
                prob['prob_desc'],
                prob['prob_type'],
                output_dir
            )

            if flowmap:
                success_count += 1
                summary.append({
                    'prob_id': prob['prob_id'],
                    'success': True,
                    'n_groups': len(flowmap.groups),
                    'n_flows': len(flowmap.flows),
                    'prob_area': prob['prob_area'],
                    'prob_point': prob['prob_point']
                })
            else:
                summary.append({
                    'prob_id': prob['prob_id'],
                    'success': False
                })

        except Exception as e:
            print(f"âœ— Fatal error: {e}")
            summary.append({
                'prob_id': prob['prob_id'],
                'success': False
            })
            continue

        # Rate limiting
        if i < len(problems):
            print("\nâ³ Waiting 5 seconds...")
            time.sleep(5)

    # Summary ì €ì¥
    summary_path = os.path.join(output_dir, 'summary.json')
    with open(summary_path, 'w', encoding='utf-8') as f:
        json.dump(summary, f, ensure_ascii=False, indent=2)

    # ìµœì¢… ë¦¬í¬íŠ¸
    print(f"\n{'='*70}")
    print(" SUMMARY")
    print(f"{'='*70}")
    print(f"Total problems:  {len(problems)}")
    print(f"Success:         {success_count}")
    print(f"Failed:          {len(problems) - success_count}")
    print(f"Success rate:    {success_count/len(problems)*100:.1f}%")

    if success_count > 0:
        successful = [s for s in summary if s['success']]
        avg_groups = sum(s['n_groups'] for s in successful) / len(successful)
        avg_flows = sum(s['n_flows'] for s in successful) / len(successful)

        print(f"\nAverage groups:  {avg_groups:.1f}")
        print(f"Average flows:   {avg_flows:.1f}")

    print(f"\nOutput directory: {output_dir}/")
    print(f"Summary file:     {summary_path}")
    print()


if __name__ == "__main__":
    main()
