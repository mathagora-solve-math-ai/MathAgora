# PoC 결과 요약: LLM 풀이 Step 정렬 시각화

> 2026-02-10 / 고운 편

## 한 줄 요약

**"LLM 풀이를 step 단위로 쪼개서, 모델 간 유사한 step끼리 연결하는 시각화"는 기술적으로 가능합니다.**
다만 문제 난이도에 따라 정렬 품질 차이가 있어, 보완이 필요한 부분도 확인했습니다.

---

## 배경: 뭘 하려는 건지

저희 시스템은 수능 수학 문제를 여러 LLM에게 동시에 풀게 하고, 그 풀이들을 비교해서 보여줍니다.
이때 교수님께서 요청하신 핵심 시각화는 이런 형태입니다:

```
  GPT-5.2           Claude Opus 4.5       Gemini 3 Pro
┌──────────────┐  ┌──────────────┐  ┌──────────────────────┐
│ 도함수 구하기 │──│ 도함수 구하기 │──│ 도함수 구하기         │
└──────────────┘  └──────────────┘  └──────────────────────┘
┌──────────────┐  ┌──────────────┐  ┌──────────────────────┐
│ 임계점 찾기   │  │ 임계점 찾기   │──│ 인수분해 및 0이 되는  │
└──────────────┘  └──────────────┘  │ 값 찾기              │
                                    └──────────────────────┘
┌──────────────┐  ┌──────────────┐  ┌──────────────────────┐
│ 극대/극소 판별│  │ 극대와 극소   │  │ 극대, 극소 판별       │
│              │  │ 판별         │  │                      │
└──────────────┘  └──────────────┘  └──────────────────────┘
       ...              ...              ...
```

**유사한 풀이 단계끼리 연결선(─)으로 이어주는 것**이 목표입니다.

이걸 구현하려면 확인해야 할 게 있습니다:

1. LLM 응답을 step 단위로 **안정적으로 쪼갤 수 있는가?**
2. 쪼갠 step 간 **유사도를 자동 계산해서 정렬할 수 있는가?**
3. 같은 모델을 여러 번 돌리면 vs 다른 모델을 쓰면, **다양성 차이가 있는가?**
4. 위 1~3이 **어려운 문제에서도 동작하는가?**

이 네 가지를 검증한 결과입니다.

---

## Step 추출 전략: 어떻게 쪼개는가

### 시도한 세 가지 방식

| 프롬프트 | 방식 | 장단점 |
|----------|------|--------|
| v1 "그냥 풀어줘" | 응답을 빈 줄(`\n\n`) 기준으로 paragraph 분리 | 모델이 자유롭게 쓰므로 step 수 예측 불가 |
| v2 "단계별로 풀어줘" | 번호 패턴(`1.`, `Step 1:`) 또는 Markdown 헤딩(`## 1)`) 탐지 | 모델마다 포맷이 달라서 파싱 불안정 |
| **v3 마커 포맷** | `[STEP title="..."]` 마커를 정규식으로 파싱 | **포맷을 지정해주니까 파싱이 확정적** |

### v3 프롬프트 (실제 사용한 것)

```
다음 수학 문제를 단계별(step-by-step)로 풀어주세요.
각 단계마다 **간결한 제목**(예: "조건 정리", "인수분해")을 붙여주세요.

출력 형식:
[STEP title="<간결한 제목>"]
<풀이 내용>

[FINAL_ANSWER]
<최종 답>
```

이 프롬프트를 주면 LLM이 이런 식으로 응답합니다:

```
[STEP title="도함수 구하기"]
f(x) = (1/3)x³ - 2x² - 12x + 4 이므로
f'(x) = x² - 4x - 12

[STEP title="극값 조건(임계점) 찾기"]
f'(x) = 0에서 x² - 4x - 12 = 0
(x-6)(x+2) = 0  →  x = 6, x = -2

[STEP title="극대/극소 위치 판별"]
...

[FINAL_ANSWER]
8 (⑤)
```

이 마커(`[STEP title="..."]`)를 정규식으로 잡으면 title과 body가 깔끔하게 분리됩니다.

### 실제 step 수 비교

| 프롬프트 | 7번 (쉬움) | 22번 (어려움) |
|----------|:----------:|:------------:|
| v1 (paragraph 분리) | 6 | **39** |
| v2 (번호/헤딩 탐지) | 13 | **44** |
| **v3 (마커 파싱)** | **4+1** | **6+1** |

v1/v2는 어려운 문제에서 분할이 폭증합니다 (구분선 `---`, 빈 줄 등을 전부 잡아버려서).
v3는 난이도와 무관하게 안정적입니다.

---

## 유사도 계산: 어떻게 "비슷한 step"을 판별하는가

### 방식

각 step의 `title + body` 텍스트에 대해 **TF-IDF 벡터**(char n-gram 2~4)를 만들고,
벡터 간 **코사인 유사도**를 계산합니다. 유사도가 0.3 이상이면 같은 그룹으로 묶습니다 (Union-Find).

char n-gram을 쓴 이유: 한국어+LaTeX 혼합 텍스트라 단어 토큰화가 어렵고,
글자 단위 n-gram이 수식 패턴(`f'(x)`, `x^2` 등)을 잘 잡아냅니다.

### 실제 예시: 7번 문제에서 3개 모델의 Step 1 비교

아래는 **GPT-5.2, Claude Opus 4.5, Gemini 3 Pro** 세 모델이 같은 문제(7번)를 풀었을 때,
각각의 **첫 번째 step 실제 응답**입니다:

> **GPT-5.2 — Step 1 "도함수 구하기"**
> ```
> f(x) = (1/3)x³ - 2x² - 12x + 4 이므로
> f'(x) = x² - 4x - 12
> ```

> **Claude Opus 4.5 — Step 1 "도함수 구하기"**
> ```
> 극대와 극소를 찾기 위해 f(x)를 미분합니다.
> f(x) = (1/3)x³ - 2x² - 12x + 4
> f'(x) = x² - 4x - 12
> ```

> **Gemini 3 Pro — Step 1 "도함수 구하기"**
> ```
> 함수 f(x) = (1/3)x³ - 2x² - 12x + 4의 극값을 구하기 위해 x에 대하여 미분합니다.
> f'(x) = x² - 4x - 12
> ```

세 응답 모두 `f'(x) = x² - 4x - 12`를 포함하고, "도함수", "미분" 등의 키워드가 공통입니다.
char n-gram TF-IDF로 계산하면 이 세 step 간 유사도가 **0.32~0.62** 범위로 나와서,
threshold(0.3) 이상이므로 **하나의 alignment group으로 자동 묶입니다.**

반면, Step 1 "도함수 구하기" vs Step 3 "극대/극소 판별"은 수식도 문맥도 다르기 때문에
유사도가 0.1 이하로 나와서 **다른 그룹으로 분리됩니다.**

### 정렬 결과 (7번, 3개 모델)

```
Group 1 (3/3 모델 참여):
  [GPT]    도함수 구하기     ↔  [Claude] 도함수 구하기  ↔  [Gemini] 도함수 구하기
  → 유사도 0.32~0.62 — 같은 수식(f'(x)=x²-4x-12)을 다루므로 높음

Group 2 (3/3):
  [GPT]    Final Answer     ↔  [Claude] Final Answer   ↔  [Gemini] Final Answer
  → 유사도 0.42~0.69 — "8", "⑤" 등 짧은 공통 텍스트

Group 3 (2/3):
  [Claude] 임계점 찾기       ↔  [Gemini] 인수분해 및 0이 되는 값 찾기
  → 유사도 0.55 — 제목은 다르지만, 본문에 (x-6)(x+2)=0 이 공통

Group 4 (2/3):
  [Claude] β-α 계산         ↔  [Gemini] 최종 계산
  → 유사도 0.68 — β-α = 6-(-2) = 8 수식이 거의 동일
```

제목이 달라도("임계점 찾기" vs "인수분해 및 0이 되는 값 찾기") **본문의 수식이 같으면 유사도가 높게** 나옵니다. 이 점이 char n-gram 방식의 장점입니다.

---

## 검증 결과 요약

### 같은 모델 반복 vs 다른 모델 — 다양성 비교

| 전략 | 7번 평균 유사도 | 22번 평균 유사도 | 다양성 |
|------|:--------------:|:---------------:|:------:|
| 같은 모델(GPT-5.2) 5회 반복 | 0.703 | 0.845 | 낮음 |
| **서로 다른 모델 5종** | **0.279** | **0.343** | **높음** |

**다양한 풀이를 보여주려면 반드시 다른 모델을 써야 합니다.**

같은 모델은 temperature를 올려도 거의 같은 풀이를 생성합니다.
GPT-5.2는 7번 문제에서 5회 모두 **step 제목까지 동일**했습니다.

반면 다른 모델을 쓰면 풀이 전략 자체가 달라집니다:

```
7번 문제 — 모델별 풀이 구조:
- GPT-5.2:  도함수 → 임계점 → 판별 → 계산              (5 step)
- Grok 4:   도함수 → 임계점 → 2계 도함수 → 판별 → 계산   (6 step)
- minimax:  도함수 → 극점 → 판정 → 정답                 (4 step)
```

Grok 4는 2계 도함수를 별도 step으로 분리하고, minimax는 판별과 계산을 합쳐서 간결하게 처리합니다.
이런 **구조적 차이가 시각화했을 때 학습 가치**가 됩니다.

### 쉬운 문제 vs 어려운 문제 비교

| 지표 | 7번 (3점) | 22번 (4점) |
|------|:---------:|:----------:|
| v3 step 수 | 4+1 | 6+1 |
| v3 응답 시간 | 4.9s | 26.0s |
| 정답 도달 | 전 모델 정답 | **전 모델 오답** |
| Alignment Group 수 | 4개 | 2개 |
| Step 1:1 대응 | 대부분 가능 | mega-group 형성 |
| Gemini 포맷 준수 | O | **X** |
| Grok 4 응답 시간 | 15.8s | **302.4s** |

어려운 문제에서는:
- 모델 간 풀이 전략이 크게 달라져서 step 단위 1:1 매칭이 어려워짐
- 일부 모델(Gemini)이 마커 포맷을 따르지 않음
- 응답 시간이 크게 늘어남 (Grok 4: 5분)

---

## 종합 결론

### 됩니다

1. **v3 마커 프롬프트**로 step을 안정적으로 추출할 수 있습니다
2. **코사인 유사도 + Union-Find**로 모델 간 유사 step 자동 정렬이 가능합니다
3. **다중 모델 전략**이 풀이 다양성 확보에 효과적입니다

### 보완이 필요합니다

| 이슈 | 대응 방안 |
|------|----------|
| 어려운 문제에서 정렬 품질 저하 | 임베딩 기반 유사도 (sentence-transformers) 도입 |
| Gemini 등 일부 모델 포맷 미준수 | fallback 파싱 로직 (Markdown 헤딩, 번호 패턴) |
| Grok 4 응답 시간 5분 | 모델별 타임아웃 + 스트리밍 중간 결과 표시 |
| minimax Final Answer 누락 | 마지막 단락 자동 추정 후처리 |

### 다음 단계 제안

1. 프론트엔드에 step 간 연결선(edge) 렌더링 PoC
2. 임베딩 유사도 vs TF-IDF 유사도 비교 실험
3. 실시간 스트리밍 중 부분 alignment 가능성 검토
